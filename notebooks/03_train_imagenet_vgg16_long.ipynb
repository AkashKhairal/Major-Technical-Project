{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327a8a7c",
   "metadata": {},
   "source": [
    "# EAST Scene Text Detection (Scratch Training) â€“ ICDAR2015\n",
    "\n",
    "**Objective**  \n",
    "To build an end-to-end scene text detection pipeline using EAST, train it from scratch,\n",
    "and establish a baseline for further lightweight detector research.\n",
    "\n",
    "**Key Focus**\n",
    "- End-to-end pipeline correctness\n",
    "- Proper evaluation using ICDAR2015 protocol\n",
    "- Recording accuracy + efficiency metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595380a",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c5eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /DATA/akash/akash_cnn/lightweight-text-detector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/akash/miniconda3/envs/PytorchEAST/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Move to project root\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"Working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a78b78",
   "metadata": {},
   "source": [
    "## Experiment CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8d753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# EXPERIMENT CONTROL\n",
    "# ===============================\n",
    "\n",
    "EXPERIMENT_NAME = \"exp3_imagenet_vgg16_long\"\n",
    "\n",
    "USE_PRETRAINED = True      # True for Exp-2\n",
    "PRETRAINED_TYPE = \"imagenet\"     # \"imagenet\" later\n",
    "\n",
    "INPUT_SIZE = 512\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b3ca2",
   "metadata": {},
   "source": [
    "## Experiment Folder Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9ecb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directories ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "EXP_ROOT = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "\n",
    "WEIGHTS_DIR = f\"{EXP_ROOT}/weights\"\n",
    "LOG_DIR = f\"{EXP_ROOT}/logs\"\n",
    "RESULTS_DIR = f\"{EXP_ROOT}/results\"\n",
    "PRED_DIR = f\"{RESULTS_DIR}/predictions\"\n",
    "\n",
    "for d in [WEIGHTS_DIR, LOG_DIR, PRED_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"Experiment directories ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71a99a",
   "metadata": {},
   "source": [
    "## Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2433503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"data/icdar2015/ch4_train_images\"\n",
    "TEST_IMG_DIR  = \"data/icdar2015/ch4_test_images\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f59d0",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076e3ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAST initialized\n"
     ]
    }
   ],
   "source": [
    "from src.models.east import EAST\n",
    "\n",
    "model = EAST(\n",
    "    cfg=\"D\",\n",
    "    weights=\"imagenet\" if USE_PRETRAINED else None\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model.__class__.__name__, \"initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fe989",
   "metadata": {},
   "source": [
    "## Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90fd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses.loss import Loss\n",
    "\n",
    "criterion = Loss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af8418",
   "metadata": {},
   "source": [
    "## DATASET + DATALOADER CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464aba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader ready\n",
      "Total training samples: 1000\n",
      "Batches per epoch: 50\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data.dataset import Dataset\n",
    "\n",
    "# -------------------------\n",
    "# Dataset\n",
    "# -------------------------\n",
    "train_dataset = Dataset(\n",
    "    data_path=TRAIN_IMG_DIR,\n",
    "    scale=0.25,\n",
    "    length=INPUT_SIZE\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# DataLoader\n",
    "# -------------------------\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(\"Train loader ready\")\n",
    "print(\"Total training samples:\", len(train_dataset))\n",
    "print(\"Batches per epoch:\", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beda477",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16661553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/60]:   0%|          | 0/50 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m epoch_cls_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     12\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[1;32m     13\u001b[0m     train_loader,\n\u001b[1;32m     14\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, gt_score, gt_geo, ignored_map \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Move to device\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     23\u001b[0m     gt_score \u001b[38;5;241m=\u001b[39m gt_score\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1272\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1272\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1274\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEAST/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    epoch_geo_loss = 0.0\n",
    "    epoch_cls_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch [{epoch+1}/{EPOCHS}]\",\n",
    "        dynamic_ncols=True\n",
    "    )\n",
    "\n",
    "    for imgs, gt_score, gt_geo, ignored_map in pbar:\n",
    "        # -------------------------\n",
    "        # Move to device\n",
    "        # -------------------------\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        gt_score = gt_score.to(DEVICE)\n",
    "        gt_geo = gt_geo.to(DEVICE)\n",
    "        ignored_map = ignored_map.to(DEVICE)\n",
    "\n",
    "        # -------------------------\n",
    "        # Forward\n",
    "        # -------------------------\n",
    "        pred_score, pred_geo = model(imgs)\n",
    "\n",
    "        # -------------------------\n",
    "        # EAST loss (guaranteed dict)\n",
    "        # -------------------------\n",
    "        loss_dict = criterion(\n",
    "            gt_score, pred_score,\n",
    "            gt_geo, pred_geo,\n",
    "            ignored_map\n",
    "        )\n",
    "\n",
    "        geo_loss = loss_dict[\"geo_loss\"]\n",
    "        cls_loss = loss_dict[\"cls_loss\"]\n",
    "\n",
    "        total_loss = geo_loss + cls_loss\n",
    "\n",
    "        # -------------------------\n",
    "        # Backward\n",
    "        # -------------------------\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # -------------------------\n",
    "        # Logging\n",
    "        # -------------------------\n",
    "        epoch_geo_loss += geo_loss.item()\n",
    "        epoch_cls_loss += cls_loss.item()\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            geo=f\"{geo_loss.item():.3f}\",\n",
    "            cls=f\"{cls_loss.item():.3f}\"\n",
    "        )\n",
    "\n",
    "    # -------------------------\n",
    "    # Epoch summary\n",
    "    # -------------------------\n",
    "    avg_geo = epoch_geo_loss / len(train_loader)\n",
    "    avg_cls = epoch_cls_loss / len(train_loader)\n",
    "\n",
    "    loss_log.append({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"geo_loss\": avg_geo,\n",
    "        \"cls_loss\": avg_cls\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch {epoch+1} Summary | \"\n",
    "        f\"Geo Loss: {avg_geo:.4f} | \"\n",
    "        f\"Cls Loss: {avg_cls:.4f}\"\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Save checkpoint\n",
    "    # -------------------------\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        f\"{WEIGHTS_DIR}/epoch_{epoch+1}.pth\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTraining finished successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2b26d",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be883067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== DATASET STATISTICS =====\")\n",
    "print(\"Train images:\", len(os.listdir(TRAIN_IMG_DIR)))\n",
    "print(\"Test images :\", len(os.listdir(TEST_IMG_DIR)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c9950b",
   "metadata": {},
   "source": [
    "## Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "total_params, trainable_params = count_params(model)\n",
    "\n",
    "print(\"===== MODEL SIZE =====\")\n",
    "print(f\"Total params     : {total_params/1e6:.2f} M\")\n",
    "print(f\"Trainable params : {trainable_params/1e6:.2f} M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81a47e",
   "metadata": {},
   "source": [
    "## FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "\n",
    "dummy = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE).to(DEVICE)\n",
    "flops, _ = profile(model, inputs=(dummy,), verbose=False)\n",
    "\n",
    "print(\"===== COMPUTE COST =====\")\n",
    "print(f\"GFLOPs @ {INPUT_SIZE}x{INPUT_SIZE}: {flops/1e9:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1916530",
   "metadata": {},
   "source": [
    "## Single Image Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from src.detect import detect\n",
    "\n",
    "model.eval()\n",
    "\n",
    "img_name = sorted(os.listdir(TEST_IMG_DIR))[0]\n",
    "img_path = os.path.join(TEST_IMG_DIR, img_name)\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "boxes = detect(img, model, DEVICE)\n",
    "\n",
    "print(\"Image:\", img_name)\n",
    "print(\"Detected boxes:\", 0 if boxes is None else len(boxes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a25291",
   "metadata": {},
   "source": [
    "## Single Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "if boxes is not None:\n",
    "    for box in boxes:\n",
    "        pts = [\n",
    "            (box[0], box[1]),\n",
    "            (box[2], box[3]),\n",
    "            (box[4], box[5]),\n",
    "            (box[6], box[7])\n",
    "        ]\n",
    "        draw.polygon(pts, outline=\"lime\", width=2)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Qualitative Result (Single Image)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f1705f",
   "metadata": {},
   "source": [
    "## Inference Time + FPS + GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "w, h = img.size\n",
    "img_r = img.resize(((w//32)*32, (h//32)*32))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,)*3, (0.5,)*3)\n",
    "])\n",
    "\n",
    "img_tensor = transform(img_r).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        _ = model(img_tensor)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(img_tensor)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "infer_time = (end - start) * 1000\n",
    "fps = 1000 / infer_time\n",
    "peak_mem = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "\n",
    "print(\"===== INFERENCE PERFORMANCE =====\")\n",
    "print(f\"Inference time : {infer_time:.2f} ms\")\n",
    "print(f\"FPS            : {fps:.2f}\")\n",
    "print(f\"Peak GPU mem   : {peak_mem:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5906ed",
   "metadata": {},
   "source": [
    "## Metrics JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f01eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "final_metrics = {\n",
    "    \"experiment\": EXPERIMENT_NAME,\n",
    "    \"dataset\": \"ICDAR2015\",\n",
    "    \"training\": loss_log[-1],\n",
    "    \"model\": {\n",
    "        \"params_million\": total_params / 1e6,\n",
    "        \"gflops\": flops / 1e9\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"time_ms\": infer_time,\n",
    "        \"fps\": fps,\n",
    "        \"gpu_mem_gb\": peak_mem\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(EXP_ROOT, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "print(\"metrics.json saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976615e",
   "metadata": {},
   "source": [
    "## Save Loss Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{LOG_DIR}/loss_log.json\", \"w\") as f:\n",
    "    json.dump(loss_log, f, indent=2)\n",
    "\n",
    "print(\"Loss log saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad662cd",
   "metadata": {},
   "source": [
    "## Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b63a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from src.detect import detect\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(sorted(os.listdir(TEST_IMG_DIR)), desc=\"Batch inference\")\n",
    "\n",
    "    for name in pbar:\n",
    "        if not name.lower().endswith((\".jpg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        pbar.set_postfix_str(name)\n",
    "\n",
    "        img = Image.open(os.path.join(TEST_IMG_DIR, name)).convert(\"RGB\")\n",
    "        boxes = detect(img, model, DEVICE)\n",
    "\n",
    "        txt_path = os.path.join(\n",
    "            PRED_DIR, f\"res_{os.path.splitext(name)[0]}.txt\"\n",
    "        )\n",
    "\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    f.write(\",\".join(str(int(v)) for v in box[:8]) + \"\\n\")\n",
    "\n",
    "print(\"Batch inference done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e2d6a",
   "metadata": {},
   "source": [
    "## ZIP Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e87f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "submit_zip = f\"{RESULTS_DIR}/submit.zip\"\n",
    "\n",
    "with zipfile.ZipFile(submit_zip, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    for file in os.listdir(PRED_DIR):\n",
    "        if file.endswith(\".txt\"):\n",
    "            z.write(os.path.join(PRED_DIR, file), arcname=file)\n",
    "\n",
    "print(\"submit.zip created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate/script.py \\\n",
    "-g=evaluate/gt.zip \\\n",
    "-s=experiments/exp1_scratch_vgg16/results/submit.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# FINAL FIXED ICDAR METRIC EXTRACTION (100% SAFE)\n",
    "# =====================================================\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "GT_ZIP = \"evaluate/gt.zip\"\n",
    "SUBMIT_ZIP = f\"{EXP_ROOT}/results/submit.zip\"\n",
    "METRICS_JSON = f\"{EXP_ROOT}/metrics.json\"\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"evaluate/script.py\",\n",
    "    f\"-g={GT_ZIP}\",\n",
    "    f\"-s={SUBMIT_ZIP}\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "output = result.stdout\n",
    "print(output)\n",
    "\n",
    "# ----------------------------\n",
    "# Safe metric extractor\n",
    "# ----------------------------\n",
    "def find_metric(pattern, text, group_idx):\n",
    "    m = re.search(pattern, text, re.IGNORECASE)\n",
    "    return float(m.group(group_idx)) if m else None\n",
    "\n",
    "# ----------------------------\n",
    "# Try standard patterns\n",
    "# ----------------------------\n",
    "precision = find_metric(\n",
    "    r\"precision[^0-9]*([0-9]+\\.[0-9]+)\", output, 1\n",
    ")\n",
    "\n",
    "recall = find_metric(\n",
    "    r\"recall[^0-9]*([0-9]+\\.[0-9]+)\", output, 1\n",
    ")\n",
    "\n",
    "f1 = find_metric(\n",
    "    r\"(f[- ]?measure|hmean)[^0-9]*([0-9]+\\.[0-9]+)\", output, 2\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Fallback: table format\n",
    "# ----------------------------\n",
    "if f1 is None:\n",
    "    rows = re.findall(\n",
    "        r\"\\|\\s*([0-9]+\\.[0-9]+)\\s*\\|\\s*([0-9]+\\.[0-9]+)\\s*\\|\\s*([0-9]+\\.[0-9]+)\\s*\\|\",\n",
    "        output\n",
    "    )\n",
    "    if rows:\n",
    "        precision, recall, f1 = map(float, rows[-1])\n",
    "\n",
    "# ----------------------------\n",
    "# Final sanity check\n",
    "# ----------------------------\n",
    "if f1 is None:\n",
    "    raise RuntimeError(\"ICDAR metrics could not be extracted. Check printed output.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save to metrics.json\n",
    "# ----------------------------\n",
    "with open(METRICS_JSON, \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "metrics[\"icdar\"] = {\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f_measure\": f1\n",
    "}\n",
    "\n",
    "with open(METRICS_JSON, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"ICDAR metrics saved successfully\")\n",
    "metrics[\"icdar\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266d60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ced021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a14e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3213e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c224cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c2720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8f0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46c11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee8343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c1540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchEAST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
